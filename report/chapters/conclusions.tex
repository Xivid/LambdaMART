We began with a basic implementation of LambdaMART, a gradient boosting decision tree algorithm for learning to rank. From our basic implementation, we found the performance bottleneck of the program and identified the key function, \texttt{find\_best\_split()}. We then performed a few different versions of optimization on this function until we could get the most optimal performing version. We first added feature blocking and instruction level parallelism
%to the \texttt{update()} function within \texttt{find\_best\_split()}.
Then, we added AVX instructions to vectorize load, store and floating point add operations within the functions. Finally, we converted all occurrences of datatype double to float to speed up the performance even further. Overall, we obtained 1.93x speedup in \texttt{update()}, 2.6x speedup in \texttt{cumulate()} and 1.18x speed up in \texttt{get\_best\_split()}. Since \texttt{find\_best\_split()} is mostly dominated by the time spent on \texttt{update()}, in total we obtained a 1.7x speedup. 

We conclude the major challenges as (1) having relatively low arithmetic computations compared with extensive data loads and stores; (2) the working set is usually too large to be stored completely within caches; and (3) the operations are highly non-sequential and unpredictable thus making vectorization difficult.
%This is our very first attempt at optimizing a single-core gradient boosting decision tree algorithm. 
Although the speedup from the optimizations is not phenomenal, we were able to have an in-depth look and understanding of how this algorithm can be modified to work optimally in a single-core setting.